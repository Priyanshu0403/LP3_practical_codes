{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c7ede8c-d6f0-4040-b5bd-9b4c005ac526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c0b2f4-b7ce-41a3-8b6f-744c3805da83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     Pedigree  Age  Outcome  \n",
       "0       0.627   50        1  \n",
       "1       0.351   31        0  \n",
       "2       0.672   32        1  \n",
       "3       0.167   21        0  \n",
       "4       2.288   33        1  \n",
       "..        ...  ...      ...  \n",
       "763     0.171   63        0  \n",
       "764     0.340   27        0  \n",
       "765     0.245   30        0  \n",
       "766     0.349   47        1  \n",
       "767     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f01600e3-c794-4452-9886-ff21bd8eda35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values:\n",
      " Pregnancies      0\n",
      "Glucose          0\n",
      "BloodPressure    0\n",
      "SkinThickness    0\n",
      "Insulin          0\n",
      "BMI              0\n",
      "Pedigree         0\n",
      "Age              0\n",
      "Outcome          0\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "Before: (768, 9)\n",
      "After: (768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Checking for null values\n",
    "print(\"Null values:\\n\",df.isna().sum(),\"\\n\\n\")\n",
    "\n",
    "# There are no null values, but as a safety measure\n",
    "print(\"Before:\", df.shape)\n",
    "df = df.dropna()\n",
    "print(\"After:\", df.shape) # This proves there are no null rows removed, implying no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741945bb-48d0-43ca-92b9-bf05a13f17b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix:\n",
      "[[70 29]\n",
      " [23 32]]\n",
      "\n",
      "Using confusion matrix...\n",
      "Acuuracy: 0.6623376623376623\n",
      "Error: 0.33766233766233766\n",
      "Precision: 0.5245901639344263\n",
      "Recall: 0.5818181818181818\n",
      "\n",
      "Using functions...\n",
      "Accuracy: 0.6623376623376623\n",
      "Error: 0.33766233766233766\n",
      "Precision: 0.5245901639344263\n",
      "Recall 0.5818181818181818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Applying KNN\n",
    "X = df.drop(columns=['Outcome'])\n",
    "y = df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Confusion matrix format\n",
    "#            Predicted\n",
    "#            N      P\n",
    "# Actual  N  TN     FP\n",
    "#         P  FN     TP\n",
    "\n",
    "TN = conf_matrix[0][0]\n",
    "FP = conf_matrix[0][1]\n",
    "FN = conf_matrix[1][0]\n",
    "TP = conf_matrix[1][1]\n",
    "\n",
    "print(\"\\nUsing confusion matrix...\")\n",
    "print(\"Acuuracy:\", (TP + TN)/(TP + FP + TN + FN))\n",
    "print(\"Error:\", (FP + FN)/(TP + FP + TN + FN))\n",
    "print(\"Precision:\", (TP)/(TP + FP))\n",
    "print(\"Recall:\", (TP)/(TP + FN))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "error = 1 - accuracy\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nUsing functions...\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Error:\", error)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall\", recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50912dcf-92d1-47ff-9276-f87660aa7701",
   "metadata": {},
   "source": [
    "# ... Code Explanation: KNN Diabetes Classification\n",
    "\n",
    "\n",
    "This Jupyter Notebook, Exp5.ipynb, implements the K-Nearest Neighbors (KNN) classification algorithm on the diabetes.csv dataset to predict diabetes status (Outcome). It then computes and compares key classification performance metrics.\n",
    "\n",
    "Code Explanation: KNN Diabetes Classification\n",
    "1. Setup and Data Loading (Cells 1, 2)\n",
    "Imports: Standard libraries pandas (pd) and numpy (np) are imported for data manipulation.\n",
    "\n",
    "Data Loading: The diabetes.csv file, containing 768 records and 9 features, is loaded into a pandas DataFrame named df. The features include Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, Pedigree, and Age. The target variable is Outcome (0 for non-diabetic, 1 for diabetic).\n",
    "\n",
    "2. Data Preprocessing (Cell 3)\n",
    "Handling Null Values:\n",
    "\n",
    "Python\n",
    "print(\"Null values:\\n\",df.isna().sum(),\"\\n\\n\")\n",
    "df = df.dropna()\n",
    "The code explicitly checks for and removes any rows containing null values. The output confirms that the initial dataset had no missing values, as the DataFrame shape remains unchanged at (768, 9) before and after the operation.\n",
    "\n",
    "3. KNN Implementation and Evaluation (Cell 4)\n",
    "This section sets up the model, trains it, and calculates the required performance metrics.\n",
    "\n",
    "Data Preparation and Splitting\n",
    "Python\n",
    "X = df.drop(columns=['Outcome'])\n",
    "y = df['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "Feature/Target Separation: The features (X) are defined as all columns except Outcome, and the target (y) is the Outcome column.\n",
    "\n",
    "Train-Test Split: The data is split into training (80%) and testing (20%) sets. Using random_state=42 ensures the split is consistent and reproducible.\n",
    "\n",
    "Model Training and Prediction\n",
    "Python\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "A K-Nearest Neighbors Classifier is initialized and then trained using the X_train and y_train data.\n",
    "\n",
    "The trained model then generates predictions (y_pred) on the unseen X_test data.\n",
    "\n",
    "Evaluation using Confusion Matrix and Metrics\n",
    "The notebook computes the Confusion Matrix first, which is the foundation for all other metrics:\n",
    "\n",
    "Python\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# ... manual calculation of metrics ...\n",
    "The resulting matrix is:\n",
    "\n",
    "( \n",
    "70\n",
    "23\n",
    "â€‹\n",
    "  \n",
    "29\n",
    "32\n",
    "â€‹\n",
    " )\n",
    "where the indices correspond to:\n",
    "\n",
    "TN (True Negatives): 70 (Non-Diabetic correctly predicted as Non-Diabetic)\n",
    "\n",
    "FP (False Positives): 29 (Non-Diabetic incorrectly predicted as Diabetic)\n",
    "\n",
    "FN (False Negatives): 23 (Diabetic incorrectly predicted as Non-Diabetic)\n",
    "\n",
    "TP (True Positives): 32 (Diabetic correctly predicted as Diabetic)\n",
    "\n",
    "The script then calculates the performance metrics in two ways: manually using the confusion matrix values and using the built-in sklearn.metrics functions. Both methods yielded the same results:\n",
    "\n",
    "Accuracy:\n",
    "\n",
    "(TP+TN)/Total=(32+70)/154â‰ˆ0.662\n",
    "Error Rate:\n",
    "\n",
    "1âˆ’Accuracyâ‰ˆ0.338\n",
    "Precision:\n",
    "\n",
    "TP/(TP+FP)=32/(32+29)â‰ˆ0.525\n",
    "Recall:\n",
    "\n",
    "TP/(TP+FN)=32/(32+23)â‰ˆ0.582"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd245ce-2636-463d-a650-3845b9b73324",
   "metadata": {},
   "source": [
    "# ...ðŸ’¬ Relevant Viva Questions and AnswersCore KNN Concepts\n",
    "\n",
    "Q: How does the K-Nearest Neighbors (KNN) algorithm make a prediction?\n",
    "\n",
    "A: KNN is a non-parametric, lazy learning algorithm that is instance-based. To classify a new data point, it finds the K nearest neighbors (data points) in the feature space based on a distance metric (e.g., Euclidean distance). The new point is then assigned the class that is most common (majority vote) among those $K$ neighbors.\n",
    "\n",
    "Q: What is the main weakness of the KNN algorithm, especially when dealing with high-dimensional data or large datasets?\n",
    "\n",
    "A: KNN is computationally expensive during the prediction phase, as it requires calculating the distance between the new data point and every single point in the training set. This is particularly slow for large datasets. Additionally, its performance degrades in high-dimensional spaces (the \"curse of dimensionality\"), as distance metrics become less meaningful.\n",
    "\n",
    "Q: Did this code apply feature scaling (like StandardScaler)? Should it have, and why?\n",
    "\n",
    "A: No, the provided code did not apply feature scaling. Yes, it absolutely should have. KNN is heavily influenced by the magnitude of the features because it relies on distance calculations. Features with larger numerical ranges (like Insulin or EstimatedSalary) will disproportionately dominate the distance calculation, regardless of their actual importance. Scaling features to a consistent range is critical for KNN performance.Evaluation Metrics\n",
    "\n",
    "Q: Based on the confusion matrix, which value represents a severe clinical error in this diabetes prediction model?\n",
    "\n",
    "A: The False Negative (FN) value, which is 23. A False Negative means the model predicted a patient was Non-Diabetic (0) when they were actually Diabetic (1). In a medical context, missing a positive diagnosis can lead to delayed treatment and severe consequences.\n",
    "\n",
    "Q: Explain the difference between Precision and Recall for this model, and why both are important\n",
    "\n",
    ".A:Precision (0.525): Out of all patients the model predicted were diabetic, only 52.5% actually were. Low precision means a high rate of False Positives (wasted follow-up tests or unnecessary worry).Recall (0.582): Out of all patients who actually have diabetes (TP + FN), the model correctly identified 58.2% of them. Recall measures the model's ability to find all the positive cases. Since minimizing False Negatives (missing a diagnosis) is medically critical, a high recall is often prioritized for screening tests.\n",
    "\n",
    "Q: How is the Error Rate related to Accuracy?\n",
    "\n",
    "A: The Error Rate is simply the complement of Accuracy.$$\\text{Error Rate} = 1 - \\text{Accuracy}$$It represents the proportion of total predictions that were incorrect ($(\\text{FP} + \\text{FN}) / \\text{Total}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c4c37-716c-4e18-8c1e-a6a2258abe59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
